void CDFfunction ( float * median , float * stdvLogNormalFrame , float * MeanLogNormalFrame , unsigned char * currentFrame , int pixelsPerFrame ) { int pixel ; for ( pixel = 0 ; pixel < pixelsPerFrame ; pixel ++ ) { float newvalue ; float x = currentFrame [ pixel ] ; newvalue = - ( ( log ( x ) - median [ pixel ] ) - MeanLogNormalFrame [ pixel ] ) / ( sqrt ( 2.0 ) * stdvLogNormalFrame [ pixel ] ) ; float summ = 0.5f + 0.5f * erf ( newvalue ) ; if ( summ >= 0.3 ) { currentFrame [ pixel ] = ( unsigned char ) 255 ; } else { currentFrame [ pixel ] = ( unsigned char ) 0 ; } } }
void mul ( float * M , float * N , float * K , float height_M , float width_N , float width_M ) { for ( int i = 0 ; i < height_M ; i ++ ) { for ( int j = 0 ; j < width_N ; j ++ ) { float sum = 0 ; for ( int k = 0 ; k < width_M ; k ++ ) { float a = M [ i * ( int ) width_M + k ] ; float b = N [ k * ( int ) width_N + j ] ; sum += a * b ; } K [ i * ( int ) width_N + j ] = sum ; } } }
void softmax_x_ent_cpu ( int n , float * pred , float * truth , float * delta , float * error ) { int i ; for ( i = 0 ; i < n ; ++ i ) { float t = truth [ i ] ; float p = pred [ i ] ; error [ i ] = ( t ) ? - log ( p ) : 0 ; delta [ i ] = t - p ; } }
void normalize_img ( double * image , long int image_size , int bands ) { long int i , j ; long int row ; double * D = ( double * ) calloc ( image_size , sizeof ( double ) ) ; for ( i = 0 ; i < image_size * bands ; i ++ ) { D [ i % image_size ] += image [ i ] ; } for ( i = 0 ; i < image_size ; i ++ ) { D [ i ] = powf ( D [ i ] + 1.0e-16 , -1 ) ; } for ( i = 0 ; i < bands ; i ++ ) { row = i * image_size ; for ( j = 0 ; j < image_size ; j ++ ) { image [ row + j ] = image [ row + j ] * D [ j ] ; } } free ( D ) ; }
void permuteData_cpu ( const float * input , float * output , int num , int devideNum , int featureSize , int priorNum , int batchSize ) { for ( int tid = 0 ; tid < num ; tid ++ ) { int numPerbatch = num * devideNum * priorNum ; for ( int s = 0 ; s < batchSize ; s ++ ) { for ( int i = 0 ; i < priorNum ; i ++ ) { for ( int j = 0 ; j < devideNum ; j ++ ) { output [ s * numPerbatch + tid * priorNum * devideNum + i * devideNum + j ] = input [ s * numPerbatch + ( i * devideNum * featureSize ) + ( j * featureSize ) + tid ] ; } } } } }
void cpuSimpleCorrelator ( float * xi , float * xq , float * sr , float * si , int sLength , float * L , int uLength ) { for ( int u = 0 ; u < uLength ; u ++ ) { float real = 0 ; float imag = 0 ; float a , b , c , d ; for ( int n = u ; n < u + sLength ; n ++ ) { a = xi [ n ] ; b = xq [ n ] ; c = sr [ n - u ] ; d = si [ n - u ] * ( -1 ) ; real += ( a * c ) - ( b * d ) ; imag += ( a * d ) + ( b * c ) ; } L [ u ] = sqrt ( real * real + imag * imag ) ; } }
void convertKinectDisparityToRegularDisparity_cpu ( float * d_regularDisparity , int d_regularDisparityPitch , const float * d_KinectDisparity , int d_KinectDisparityPitch , int width , int height ) { for ( int x = 0 ; x < width ; x ++ ) { for ( int y = 0 ; y < height ; y ++ ) { float d_in = * ( ( float * ) ( ( char * ) d_KinectDisparity + y * d_KinectDisparityPitch ) + x ) ; float d_out = ( d_in == 0.0f ) ? 1 : - d_in ; * ( ( float * ) ( ( char * ) d_regularDisparity + y * d_regularDisparityPitch ) + x ) = d_out ; } } }
void runFilterCpu ( float * I , float * Q , int samplesLength , float * filter , int filterLength , float * filtered_I , float * filtered_Q , int convLength ) { for ( int sampleIndex = 0 ; sampleIndex < convLength ; sampleIndex ++ ) { int index ; float sumI , sumQ ; sumI = 0 ; sumQ = 0 ; for ( int j = sampleIndex - filterLength + 1 ; j <= sampleIndex ; j ++ ) { index = sampleIndex - j ; if ( ( j < samplesLength ) && ( j >= 0 ) ) { sumI += filter [ index ] * I [ j ] ; sumQ += filter [ index ] * Q [ j ] ; } } filtered_I [ sampleIndex ] = sumI ; filtered_Q [ sampleIndex ] = sumQ ; } }
void l2normalize_cpu ( float * x , float * dx , int batch , int filters , int spatial ) { int b , f , i ; for ( b = 0 ; b < batch ; ++ b ) { for ( i = 0 ; i < spatial ; ++ i ) { float sum = 0 ; for ( f = 0 ; f < filters ; ++ f ) { int index = b * filters * spatial + f * spatial + i ; sum += powf ( x [ index ] , 2 ) ; } sum = sqrtf ( sum ) ; for ( f = 0 ; f < filters ; ++ f ) { int index = b * filters * spatial + f * spatial + i ; x [ index ] /= sum ; dx [ index ] = ( 1 - x [ index ] ) / sum ; } } } }
void distanceMatCalc ( long int totalPixels , int availablePixels , int outPixelOffset , int patchSize , float * distMat , float * data , float filtSig ) { for ( long int i = 0 ; i < availablePixels * totalPixels ; i ++ ) { int data_i = i / totalPixels + outPixelOffset ; int data_j = i % totalPixels ; float tmp = 0.0 ; if ( data_i != data_j ) { for ( int elem = 0 ; elem < patchSize * patchSize ; elem ++ ) { float diff = ( data [ data_i * patchSize * patchSize + elem ] - data [ data_j * patchSize * patchSize + elem ] ) ; tmp += diff * diff ; } tmp = exp ( - tmp / ( filtSig ) ) ; } distMat [ i ] = tmp ; } }
void shortcut_kernel_cpu ( int size , int minw , int minh , int minc , int stride , int sample , int batch , int w1 , int h1 , int c1 , float * add , int w2 , int h2 , int c2 , float * out ) { for ( int id = 0 ; id < size ; id ++ ) { int i = id % minw ; id /= minw ; int j = id % minh ; id /= minh ; int k = id % minc ; id /= minc ; int b = id % batch ; int out_index = i * sample + w2 * ( j * sample + h2 * ( k + c2 * b ) ) ; int add_index = i * stride + w1 * ( j * stride + h1 * ( k + c1 * b ) ) ; out [ out_index ] += add [ add_index ] ; } }
float dot_cpu ( int N , float * X , int INCX , float * Y , int INCY ) { int i ; float dot = 0 ; for ( i = 0 ; i < N ; ++ i ) dot += X [ i * INCX ] * Y [ i * INCY ] ; return dot ; }
void k_adam_kernel ( float * m , float * v , float * w , const float * d , int max_size , float beta1 , float beta2 , float beta1_tpower , float beta2_tpower , float learning_rate ) { const float eps = 1e-8 ; for ( int i = 0 ; i < max_size ; i ++ ) { float d_temp = d [ i ] ; m [ i ] = m [ i ] * beta1 + d_temp * ( 1 - beta1 ) ; v [ i ] = v [ i ] * beta2 + d_temp * d_temp * ( 1 - beta2 ) ; float m_hat = m [ i ] / ( 1 - beta1_tpower ) ; float v_hat = sqrt ( v [ i ] / ( 1 - beta2_tpower ) ) + eps ; w [ i ] += ( m_hat / v_hat ) * ( - learning_rate ) ; } }
void convLayer_forward ( int N , int M , int C , int H , int W , int K , float * X , float * Wk , float * Y ) { int n , m , c , h , w , p , q ; int H_out = H - K + 1 ; int W_out = W - K + 1 ; for ( n = 0 ; n < N ; n ++ ) for ( m = 0 ; m < M ; m ++ ) for ( h = 0 ; h < H_out ; h ++ ) for ( w = 0 ; w < W_out ; w ++ ) { Y [ n , m , h , w ] = 0 ; for ( c = 0 ; c < C ; c ++ ) for ( p = 0 ; p < K ; p ++ ) for ( q = 0 ; q < K ; q ++ ) Y [ n , m , h , w ] += X [ n , c , h + p , w + q ] * Wk [ m , c , p , q ] ; } }
void opL23_cpu ( float * vec , float * vec1 , long depth , long rows , long cols ) { for ( int x = 0 ; x < cols ; x ++ ) { for ( int y = 0 ; y < rows ; y ++ ) { for ( int z = 0 ; z < depth ; x ++ ) { unsigned long long i = z * rows * cols + y * cols + x ; unsigned long long j = z * rows * cols + y * cols ; unsigned long size2d = cols ; unsigned long size3d = depth * rows * cols + rows * cols + cols ; if ( i + cols + 1 >= size3d ) return ; vec [ i + cols ] = 0.5 * ( vec1 [ i + cols ] + vec1 [ i ] ) ; if ( j + 1 >= size2d ) return ; vec [ j ] = 0.5 * ( vec1 [ j ] ) ; } } } }
void upsample_cpu ( float * in , int w , int h , int c , int batch , int stride , int forward , float scale , float * out ) { int i , j , k , b ; for ( b = 0 ; b < batch ; ++ b ) { for ( k = 0 ; k < c ; ++ k ) { for ( j = 0 ; j < h * stride ; ++ j ) { for ( i = 0 ; i < w * stride ; ++ i ) { int in_index = b * w * h * c + k * w * h + ( j / stride ) * w + i / stride ; int out_index = b * w * h * c * stride * stride + k * w * h * stride * stride + j * w * stride + i ; if ( forward ) out [ out_index ] = scale * in [ in_index ] ; else in [ in_index ] += scale * out [ out_index ] ; } } } } }
void rgb2yuv_kernel ( int img_size , unsigned char * gpu_img_in_r , unsigned char * gpu_img_in_g , unsigned char * gpu_img_in_b , unsigned char * gpu_img_out_y , unsigned char * gpu_img_out_u , unsigned char * gpu_img_out_v ) { unsigned char r , g , b ; int index ; for ( index = 0 ; index < img_size ; index ++ ) { r = gpu_img_in_r [ index ] ; g = gpu_img_in_g [ index ] ; b = gpu_img_in_b [ index ] ; gpu_img_out_y [ index ] = ( unsigned char ) ( 0.299 * r + 0.587 * g + 0.114 * b ) ; gpu_img_out_u [ index ] = ( unsigned char ) ( -0.169 * r - 0.331 * g + 0.499 * b + 128 ) ; gpu_img_out_v [ index ] = ( unsigned char ) ( 0.499 * r - 0.418 * g - 0.0813 * b + 128 ) ; } }
void getDRho ( const int numOfNucl , const double * psi , const double * * dpsi , const double * occNo , double * drho , const char debug ) { drho [ 0 ] = 0 ; drho [ 1 ] = 0 ; drho [ 2 ] = 0 ; for ( int i = 0 ; i < numOfNucl ; ++ i ) { drho [ 0 ] = drho [ 0 ] + 2 * occNo [ i ] * psi [ i ] * dpsi [ i ] [ 0 ] ; drho [ 1 ] = drho [ 1 ] + 2 * occNo [ i ] * psi [ i ] * dpsi [ i ] [ 1 ] ; drho [ 2 ] = drho [ 2 ] + 2 * occNo [ i ] * psi [ i ] * dpsi [ i ] [ 2 ] ; } if ( debug == 1 ) printf ( " DEBUG ▁ print ▁ of ▁ DRHO : \n ▁ \t % f\t % f\t % f \n This ▁ is ▁ the ▁ last ▁ line ( DRHO ) . \n \n " , drho [ 0 ] , drho [ 1 ] , drho [ 2 ] ) ; }
void opL12_cpu ( float * vec , float * vec1 , long depth , long rows , long cols ) { for ( int x = 0 ; x < cols ; x ++ ) { for ( int y = 0 ; y < rows ; y ++ ) { for ( int z = 0 ; z < depth ; x ++ ) { unsigned long long i = z * rows * cols + y * cols + x ; unsigned long long j = z * rows * cols + y * cols ; unsigned long size2d = cols ; unsigned long size3d = depth * rows * cols + rows * cols + cols ; if ( i + cols + 1 >= size3d ) return ; vec [ i + 1 ] = 0.25 * ( vec1 [ i + 1 ] + vec1 [ i ] + vec1 [ i + cols + 1 ] + vec1 [ i + cols ] ) ; if ( j + 1 >= size2d ) return ; vec [ j ] = 0.25 * ( vec1 [ j ] + vec1 [ j + cols ] ) ; } } } }
void cpuBYUSimplified ( float * xi , float * xq , float * sr , float * si , int N , int Lq , float * L ) { for ( int u = 0 ; u < N ; u ++ ) { float uSum = 0 ; float r_i , r_q , q_i , q_q ; float realPart , imagPart ; for ( int k = 0 ; k <= 7 ; k ++ ) { realPart = 0 ; imagPart = 0 ; for ( int l = 0 ; l < Lq ; l ++ ) { r_i = xi [ u + k * Lq + l ] ; r_q = xq [ u + k * Lq + l ] ; q_i = sr [ l ] ; q_q = si [ l ] * ( -1 ) ; realPart += ( r_i * q_i ) - ( r_q * q_q ) ; imagPart += ( r_i * q_q ) + ( r_q * q_i ) ; } uSum += ( realPart * realPart ) + ( imagPart * imagPart ) ; } L [ u ] = uSum ; } }
void shortcut_cpu ( int batch , int w1 , int h1 , int c1 , float * add , int w2 , int h2 , int c2 , float s1 , float s2 , float * out ) { int stride = w1 / w2 ; int sample = w2 / w1 ; assert ( stride == h1 / h2 ) ; assert ( sample == h2 / h1 ) ; if ( stride < 1 ) stride = 1 ; if ( sample < 1 ) sample = 1 ; int minw = ( w1 < w2 ) ? w1 : w2 ; int minh = ( h1 < h2 ) ? h1 : h2 ; int minc = ( c1 < c2 ) ? c1 : c2 ; int i , j , k , b ; for ( b = 0 ; b < batch ; ++ b ) { for ( k = 0 ; k < minc ; ++ k ) { for ( j = 0 ; j < minh ; ++ j ) { for ( i = 0 ; i < minw ; ++ i ) { int out_index = i * sample + w2 * ( j * sample + h2 * ( k + c2 * b ) ) ; int add_index = i * stride + w1 * ( j * stride + h1 * ( k + c1 * b ) ) ; out [ out_index ] = s1 * out [ out_index ] + s2 * add [ add_index ] ; } } } } }
void get_before_nms_data_cpu ( const float * boxes , const float * scores , const int * labels , const int * index , float * boxes_out , float * scores_out , int * labels_out , int dims ) { for ( int tid = 0 ; tid < dims ; tid ++ ) { if ( index [ tid ] == 0 ) { boxes_out [ tid * 4 + 0 ] = -1 ; boxes_out [ tid * 4 + 1 ] = -1 ; boxes_out [ tid * 4 + 2 ] = -1 ; boxes_out [ tid * 4 + 3 ] = -1 ; scores_out [ tid ] = -1 ; labels_out [ tid ] = -1 ; } else { boxes_out [ tid * 4 + 0 ] = boxes [ tid * 4 + 0 ] ; boxes_out [ tid * 4 + 1 ] = boxes [ tid * 4 + 1 ] ; boxes_out [ tid * 4 + 2 ] = boxes [ tid * 4 + 2 ] ; boxes_out [ tid * 4 + 3 ] = boxes [ tid * 4 + 3 ] ; scores_out [ tid ] = scores [ tid ] ; labels_out [ tid ] = labels [ tid ] ; } } }
void im2col_cpu ( float * data_im , int channels , int height , int width , int ksize , int stride , int pad , float * data_col ) { int c , h , w ; int height_col = ( height + 2 * pad - ksize ) / stride + 1 ; int width_col = ( width + 2 * pad - ksize ) / stride + 1 ; int channels_col = channels * ksize * ksize ; for ( c = 0 ; c < channels_col ; ++ c ) { int w_offset = c % ksize ; int h_offset = ( c / ksize ) % ksize ; int c_im = c / ksize / ksize ; for ( h = 0 ; h < height_col ; ++ h ) { for ( w = 0 ; w < width_col ; ++ w ) { int im_row = h_offset + h * stride ; int im_col = w_offset + w * stride ; int col_index = ( c * height_col + h ) * width_col + w ; data_col [ col_index ] = im2col_get_pixel ( data_im , height , width , channels , im_row , im_col , c_im , pad ) ; } } } }
void getTopkNum ( const float * inputScore , const int * inputIndex , float * outputScore , int * outputIndex , float threshold , const int dims , int * anchorIndex , int * classIndex , const int classNum , int batchSize , int totalScoreNum ) { for ( int tid = 0 ; tid < dims ; tid ++ ) { for ( int i = 0 ; i < batchSize ; i ++ ) { if ( inputScore [ i * totalScoreNum + tid ] >= threshold ) { outputScore [ i * dims + tid ] = inputScore [ i * totalScoreNum + tid ] ; outputIndex [ i * dims + tid ] = inputIndex [ i * totalScoreNum + tid ] ; anchorIndex [ i * dims + tid ] = outputIndex [ i * dims + tid ] / classNum ; classIndex [ i * dims + tid ] = outputIndex [ i * dims + tid ] % classNum ; } else { outputScore [ i * dims + tid ] = 0.0f ; outputIndex [ i * dims + tid ] = -1 ; anchorIndex [ i * dims + tid ] = -1 ; classIndex [ i * dims + tid ] = -1 ; } } } }
void fractal_cpu ( const int width , const int frames , unsigned char * const pic ) { for ( int i = 0 ; i < width * width * frames ; i ++ ) { const float Delta = 0.00304f ; const float xMid = -0.055846456f ; const float yMid = -0.668311119f ; const int frame = i / ( width * width ) ; float delta = Delta * powf ( 0.975f , frame ) ; const int col = i % width ; const float xMin = xMid - delta ; const float yMin = yMid - delta ; const float dw = 2.0f * delta / width ; const int row = ( i / width ) % width ; const float cy = yMin + row * dw ; const float cx = xMin + col * dw ; float x = cx ; float y = cy ; float x2 , y2 ; int count = 256 ; do { x2 = x * x ; y2 = y * y ; y = 2.0 * x * y + cy ; x = x2 - y2 + cx ; count -- ; } while ( ( count > 0 ) && ( ( x2 + y2 ) <= 5.0 ) ) ; pic [ frame * width * width + row * width + col ] = ( unsigned char ) count ; } }
void bit8Channels_cpu ( unsigned char * out , unsigned char * in , int channel , int n ) { for ( int i = 0 ; i < n ; i ++ ) { int firstIndexToGrab = i * 8 ; unsigned char bit0 = ( in [ firstIndexToGrab + 0 ] & 0x01 ) << 0 ; unsigned char bit1 = ( in [ firstIndexToGrab + 1 ] & 0x01 ) << 1 ; unsigned char bit2 = ( in [ firstIndexToGrab + 2 ] & 0x01 ) << 2 ; unsigned char bit3 = ( in [ firstIndexToGrab + 3 ] & 0x01 ) << 3 ; unsigned char bit4 = ( in [ firstIndexToGrab + 4 ] & 0x01 ) << 4 ; unsigned char bit5 = ( in [ firstIndexToGrab + 5 ] & 0x01 ) << 5 ; unsigned char bit6 = ( in [ firstIndexToGrab + 6 ] & 0x01 ) << 6 ; unsigned char bit7 = ( in [ firstIndexToGrab + 7 ] & 0x01 ) << 7 ; unsigned char output = bit7 | bit6 | bit5 | bit4 | bit3 | bit2 | bit1 | bit0 ; int outputIndex = i * 8 + channel - 1 ; out [ outputIndex ] = output ; } }
void * Match ( int num_points , float * P , float * Q , int q_points , int * idx , int start , int end ) { float dist ; float max_dist = 1000000000.0f ; for ( int i = start ; i < end ; i ++ ) { max_dist = 1000000000.0f ; for ( int j = 0 ; j < num_points ; j ++ ) { dist = ( P [ 0 + i * 3 ] - Q [ 0 + j * 3 ] ) * ( P [ 0 + i * 3 ] - Q [ 0 + j * 3 ] ) + ( P [ 1 + i * 3 ] - Q [ 1 + j * 3 ] ) * ( P [ 1 + i * 3 ] - Q [ 1 + j * 3 ] ) + ( P [ 2 + i * 3 ] - Q [ 2 + j * 3 ] ) * ( P [ 2 + i * 3 ] - Q [ 2 + j * 3 ] ) ; if ( dist < max_dist ) { max_dist = dist ; idx [ i ] = j ; } } } return ( void * ) 0 ; }
void col2im_cpu ( float * data_col , int channels , int height , int width , int ksize , int stride , int pad , float * data_im ) { int c , h , w ; int height_col = ( height + 2 * pad - ksize ) / stride + 1 ; int width_col = ( width + 2 * pad - ksize ) / stride + 1 ; int channels_col = channels * ksize * ksize ; for ( c = 0 ; c < channels_col ; ++ c ) { int w_offset = c % ksize ; int h_offset = ( c / ksize ) % ksize ; int c_im = c / ksize / ksize ; for ( h = 0 ; h < height_col ; ++ h ) { for ( w = 0 ; w < width_col ; ++ w ) { int im_row = h_offset + h * stride ; int im_col = w_offset + w * stride ; int col_index = ( c * height_col + h ) * width_col + w ; float val = data_col [ col_index ] ; col2im_add_pixel ( data_im , height , width , channels , im_row , im_col , c_im , pad , val ) ; } } } }
void yuv2rgb_kernel ( int img_size , unsigned char * gpu_img_in_y , unsigned char * gpu_img_in_u , unsigned char * gpu_img_in_v , unsigned char * gpu_img_out_r , unsigned char * gpu_img_out_g , unsigned char * gpu_img_out_b ) { int rt , gt , bt ; int rt2 , gt2 , bt2 ; int index ; for ( index = 0 ; index < img_size ; index ++ ) { rt = ( int ) ( gpu_img_in_y [ index ] + 1.402 * ( gpu_img_in_v [ index ] - 128 ) ) ; gt = ( int ) ( gpu_img_in_y [ index ] - 0.344 * ( gpu_img_in_u [ index ] - 128 ) - 0.714 * ( gpu_img_in_v [ index ] - 128 ) ) ; bt = ( int ) gpu_img_in_y [ index ] + 1.772 * ( gpu_img_in_u [ index ] - 128 ) ; rt2 = ( rt > 255 ) ? 255 : rt ; gt2 = ( gt > 255 ) ? 255 : gt ; bt2 = ( bt > 255 ) ? 255 : bt ; gpu_img_out_r [ index ] = ( rt2 < 0 ) ? 0 : rt2 ; gpu_img_out_b [ index ] = ( bt2 < 0 ) ? 0 : bt2 ; gpu_img_out_g [ index ] = ( gt2 < 0 ) ? 0 : gt2 ; } }
void get_boxes_for_nms_cpu ( const float * boxes_before_nms , const float * offset , float * boxes_for_nms , int dims ) { for ( int tid = 0 ; tid < dims ; tid ++ ) { if ( boxes_before_nms [ tid * 4 + 0 ] == ( -1 ) && boxes_before_nms [ tid * 4 + 1 ] == ( -1 ) && boxes_before_nms [ tid * 4 + 2 ] == ( -1 ) && boxes_before_nms [ tid * 4 + 3 ] == ( -1 ) ) { boxes_for_nms [ tid * 4 + 0 ] = ( -1 ) ; boxes_for_nms [ tid * 4 + 1 ] = ( -1 ) ; boxes_for_nms [ tid * 4 + 2 ] = ( -1 ) ; boxes_for_nms [ tid * 4 + 3 ] = ( -1 ) ; } else { boxes_for_nms [ tid * 4 + 0 ] = boxes_before_nms [ tid * 4 + 0 ] + offset [ tid ] ; boxes_for_nms [ tid * 4 + 1 ] = boxes_before_nms [ tid * 4 + 1 ] + offset [ tid ] ; boxes_for_nms [ tid * 4 + 2 ] = boxes_before_nms [ tid * 4 + 2 ] + offset [ tid ] ; boxes_for_nms [ tid * 4 + 3 ] = boxes_before_nms [ tid * 4 + 3 ] + offset [ tid ] ; } } }
void eltwise_cpu ( int batch , int w1 , int h1 , int c1 , float * add , int w2 , int h2 , int c2 , float * out , int sum , int mult ) { int stride = w1 / w2 ; int sample = w2 / w1 ; assert ( stride == h1 / h2 ) ; assert ( sample == h2 / h1 ) ; if ( stride < 1 ) stride = 1 ; if ( sample < 1 ) sample = 1 ; int minw = ( w1 < w2 ) ? w1 : w2 ; int minh = ( h1 < h2 ) ? h1 : h2 ; int minc = ( c1 < c2 ) ? c1 : c2 ; int i , j , k , b ; if ( mult == 1 ) { for ( b = 0 ; b < batch ; ++ b ) { for ( k = 0 ; k < minc ; ++ k ) { for ( j = 0 ; j < minh ; ++ j ) { for ( i = 0 ; i < minw ; ++ i ) { int out_index = i * sample + w2 * ( j * sample + h2 * ( k + c2 * b ) ) ; int add_index = i * stride + w1 * ( j * stride + h1 * ( k + c1 * b ) ) ; out [ out_index ] = out [ out_index ] * add [ add_index ] ; } } } } } else if ( sum == 1 ) { for ( b = 0 ; b < batch ; ++ b ) { for ( k = 0 ; k < minc ; ++ k ) { for ( j = 0 ; j < minh ; ++ j ) { for ( i = 0 ; i < minw ; ++ i ) { int out_index = i * sample + w2 * ( j * sample + h2 * ( k + c2 * b ) ) ; int add_index = i * stride + w1 * ( j * stride + h1 * ( k + c1 * b ) ) ; out [ out_index ] = out [ out_index ] + add [ add_index ] ; } } } } } }
void decode_cpu ( const float * anchor , const float * locData , float * predictBox , int dims , float scaleClamp , int batchSize ) { for ( int tid = 0 ; tid < dims ; tid ++ ) { for ( int i = 0 ; i < batchSize ; i ++ ) { float anchorW = anchor [ i * dims * 4 + tid * 4 + 2 ] - anchor [ i * dims * 4 + tid * 4 ] ; float anchorH = anchor [ i * dims * 4 + tid * 4 + 3 ] - anchor [ i * dims * 4 + tid * 4 + 1 ] ; float anchorCx = anchor [ i * dims * 4 + tid * 4 ] + 0.5 * anchorW ; float anchorCy = anchor [ i * dims * 4 + tid * 4 + 1 ] + 0.5 * anchorH ; float dx = locData [ i * dims * 4 + tid * 4 ] ; float dy = locData [ i * dims * 4 + tid * 4 + 1 ] ; float dw = locData [ i * dims * 4 + tid * 4 + 2 ] ; float dh = locData [ i * dims * 4 + tid * 4 + 3 ] ; if ( dw > scaleClamp ) { dw = scaleClamp ; } if ( dh > scaleClamp ) { dh = scaleClamp ; } float preCx = dx * anchorW + anchorCx ; float preCy = dy * anchorH + anchorCy ; float preW = anchorW * 0.5 ; float preH = anchorH * 0.5 ; predictBox [ i * dims * 4 + tid * 4 ] = preCx - 0.5 * preW ; predictBox [ i * dims * 4 + tid * 4 + 1 ] = preCy - 0.5 * preH ; predictBox [ i * dims * 4 + tid * 4 + 2 ] = preCx + 0.5 * preW ; predictBox [ i * dims * 4 + tid * 4 + 3 ] = preCy + 0.5 * preH ; } } }
void nlf_down_forward_cpu ( const int n , const float * filters , const int channel , const int height , const int width , const int wsize , float * top_data ) { for ( int index = 0 ; index < n ; index ++ ) { int step = height * width ; int base = index * step ; int fbase = index / channel * wsize * step ; for ( int row = 0 ; row < height ; row ++ ) { for ( int col = 0 ; col < width ; col ++ ) { float temp = 0 ; int r = row ; int c = col ; int shift = 0 * step + row * width + col ; temp += top_data [ base + r * width + c ] * filters [ fbase + shift ] ; r = row - 1 ; c = col ; shift = 1 * step + row * width + col ; if ( r >= 0 ) temp += top_data [ base + r * width + c ] * filters [ fbase + shift ] ; else temp += top_data [ base + row * width + col ] * filters [ fbase + shift ] ; r = row - 1 ; c = col - 1 ; shift = 2 * step + row * width + col ; if ( r >= 0 && c >= 0 ) temp += top_data [ base + r * width + c ] * filters [ fbase + shift ] ; else temp += top_data [ base + row * width + col ] * filters [ fbase + shift ] ; r = row - 1 ; c = col + 1 ; shift = 3 * step + row * width + col ; if ( r >= 0 && c < width ) temp += top_data [ base + r * width + c ] * filters [ fbase + shift ] ; else temp += top_data [ base + row * width + col ] * filters [ fbase + shift ] ; r = row ; c = col - 1 ; shift = 4 * step + row * width + col ; if ( c >= 0 ) temp += top_data [ base + r * width + c ] * filters [ fbase + shift ] ; else temp += top_data [ base + row * width + col ] * filters [ fbase + shift ] ; top_data [ base + row * width + col ] = temp ; } } } }
void nlf_filter_left_backward_cpu ( const int n , const float * bottom_data , const float * top_data , const float * temp_diff , const int channel , const int height , const int width , const int wsize , float * filters_diff ) { for ( int index = 0 ; index < n ; index ++ ) { int step = height * width ; int base = index / step * step * channel + index % step ; int fbase = index / step * step * wsize + index % step ; int row = index % step / width ; int col = index % step % width ; for ( int i = 0 ; i < channel ; i ++ ) { filters_diff [ fbase ] += temp_diff [ base + i * step ] * bottom_data [ base + i * step ] ; if ( col + 1 < width ) filters_diff [ fbase + step ] += temp_diff [ base + i * step ] * top_data [ base + 1 + i * step ] ; else filters_diff [ fbase + step ] += temp_diff [ base + i * step ] * bottom_data [ base + i * step ] ; if ( col + 1 < width && row - 1 >= 0 ) filters_diff [ fbase + 2 * step ] += temp_diff [ base + i * step ] * top_data [ base - width + 1 + i * step ] ; else filters_diff [ fbase + 2 * step ] += temp_diff [ base + i * step ] * bottom_data [ base + i * step ] ; if ( col + 1 < width && row + 1 < height ) filters_diff [ fbase + 3 * step ] += temp_diff [ base + i * step ] * top_data [ base + width + 1 + i * step ] ; else filters_diff [ fbase + 3 * step ] += temp_diff [ base + i * step ] * bottom_data [ base + i * step ] ; if ( row + 1 < height ) filters_diff [ fbase + 4 * step ] += temp_diff [ base + i * step ] * top_data [ base + width + i * step ] ; else filters_diff [ fbase + 4 * step ] += temp_diff [ base + i * step ] * bottom_data [ base + i * step ] ; } } }
void nlf_filter_down_backward_cpu ( const int n , const float * bottom_data , const float * top_data , const float * temp_diff , const int channel , const int height , const int width , const int wsize , float * filters_diff ) { for ( int index = 0 ; index < n ; index ++ ) { int step = height * width ; int base = index / step * step * channel + index % step ; int fbase = index / step * step * wsize + index % step ; int row = index % step / width ; int col = index % step % width ; for ( int i = 0 ; i < channel ; i ++ ) { filters_diff [ fbase ] += temp_diff [ base + i * step ] * bottom_data [ base + i * step ] ; if ( row - 1 >= 0 ) filters_diff [ fbase + step ] += temp_diff [ base + i * step ] * top_data [ base - width + i * step ] ; else filters_diff [ fbase + step ] += temp_diff [ base + i * step ] * bottom_data [ base + i * step ] ; if ( row - 1 >= 0 && col - 1 >= 0 ) filters_diff [ fbase + 2 * step ] += temp_diff [ base + i * step ] * top_data [ base - width - 1 + i * step ] ; else filters_diff [ fbase + 2 * step ] += temp_diff [ base + i * step ] * bottom_data [ base + i * step ] ; if ( row - 1 >= 0 && col + 1 < width ) filters_diff [ fbase + 3 * step ] += temp_diff [ base + i * step ] * top_data [ base - width + 1 + i * step ] ; else filters_diff [ fbase + 3 * step ] += temp_diff [ base + i * step ] * bottom_data [ base + i * step ] ; if ( col - 1 >= 0 ) filters_diff [ fbase + 4 * step ] += temp_diff [ base + i * step ] * top_data [ base - 1 + i * step ] ; else filters_diff [ fbase + 4 * step ] += temp_diff [ base + i * step ] * bottom_data [ base + i * step ] ; } } }
void nlf_up_forward_cpu ( const int n , const float * filters , const int channel , const int height , const int width , const int wsize , float * top_data ) { for ( int index = 0 ; index < n ; index ++ ) { int step = height * width ; int base = index * step ; int fbase = index / channel * wsize * step ; for ( int row = height - 1 ; row >= 0 ; row -- ) { for ( int col = width - 1 ; col >= 0 ; col -- ) { float temp = 0 ; int r = row ; int c = col ; int shift = 0 * step + row * width + col ; temp += top_data [ base + r * width + c ] * filters [ fbase + shift ] ; r = row + 1 ; c = col ; shift = 1 * step + row * width + col ; if ( r < height ) temp += top_data [ base + r * width + c ] * filters [ fbase + shift ] ; else temp += top_data [ base + row * width + col ] * filters [ fbase + shift ] ; r = row + 1 ; c = col - 1 ; shift = 2 * step + row * width + col ; if ( r < height && c >= 0 ) temp += top_data [ base + r * width + c ] * filters [ fbase + shift ] ; else temp += top_data [ base + row * width + col ] * filters [ fbase + shift ] ; r = row + 1 ; c = col + 1 ; shift = 3 * step + row * width + col ; if ( r < height && c < width ) temp += top_data [ base + r * width + c ] * filters [ fbase + shift ] ; else temp += top_data [ base + row * width + col ] * filters [ fbase + shift ] ; r = row ; c = col + 1 ; shift = 4 * step + row * width + col ; if ( c < width ) temp += top_data [ base + r * width + c ] * filters [ fbase + shift ] ; else temp += top_data [ base + row * width + col ] * filters [ fbase + shift ] ; top_data [ base + row * width + col ] = temp ; } } } }